dtmc

//values for agent process (not used)

const double beta = 0.1;
const double e = 2.718281828459045;




//locations in area

const int l;
const int approach_gap; 
const int wait_at_gap;






module _5ht_hypothesis
	

	_5HT : [0..3] init 0;
	vis1 : [0..1] init 0;
	vis2 : [0..5] init 0;
	pos : [0..10] init 0;
	move_to_reward : bool init false; //agent is attempting to move to reward, allowing for orientation adjustment
	orientation_correct: bool init false; //agent is at reward location following orientation adjustment
	reward_present : bool init false; //reward has appeared at reward location
	reward_collected : bool init false; //reward has been collected
	reward_not_collected : bool init false; //agent fails to collect reward


	[seesGap] vis1=0 -> 0.1 : (vis1'=1) + 0.9 : (vis1' = 0);

	[updatePosition] vis1=1 & pos<l & move_to_reward=false -> (pos'= pos + speed); 	


	[entersPF] pos>=approach_gap & pos<wait_at_gap -> (_5HT'= 1);

	[inFrontOfGap] pos>=wait_at_gap & _5HT<3 -> (_5HT'= 3);
	[inFrontOfGap] pos< l & pos>=wait_at_gap & reward_present=false -> 0.1 : (reward_present' = true) + 0.9 : (reward_present'= false);
	
	[seeReward] reward_present= true & vis2<5 -> (vis2'=5);


	[moveToReward] pos>=l & move_to_reward=false -> (move_to_reward'=true);//the agent is moving to the location of the reward


	[correctOrientation] move_to_reward = true & orientation_correct=false-> 0.3 : (orientation_correct'=true) + 0.7 : (orientation_correct'=false);//

	
	//end states
	
	[claimReward] reward_present=true & orientation_correct=true & reward_not_collected = false -> (reward_collected'=true);

	[claimReward] reward_present=false & orientation_correct=true & reward_collected = false -> (reward_not_collected'=true);
	

endmodule


formula speed = (3 - _5HT) + x;

formula x = vis1 + vis2;




	

