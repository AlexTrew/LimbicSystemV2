dtmc

const int approach_gap; //int defining the boundary of the pf associated with reward
const int wait_at_gap; //int defining boundary of area "next to" gap containing reward
const int l; //size of the scale representing the entire explorable area (add 10 as a safety buffer)
const int delay; //number of steps to wait to spawn reward once agent waits at gap
const int reward_lifetime; //number of steps to wait before reward despawns after its instantiation

const double correct_angle_prob = 0.4;

global reward_present : bool init false; 
global at_gap : bool init false; //agent is slowing in fornt of the gap the gap

//1/6 probablility that alpha 1 or alpha 2 angle
module limbic_system



vis1 : [0..1] init 0;//visual input to speed gained when agent can see gap
vis2: [0..1];//  visual input to speed gained when agent can see reward
_5ht : [0..3] init 0;// serotonin/5HTR1/5HTR2 value
pos : [0..200] init 0;//position of agent
s : [0..10] init 0;  //state counter to help ordering of events


approach_angle_correct : bool init false;
orientation_correct : bool init false;
at_reward : bool init false;
collected_reward : bool init false;
missed_reward : bool init false;

[] s=0 -> 0.2 : (vis1'=1) & (s'=1) + 0.8 : (vis1'=0) & (s'=0); // see area containing reward and end exploration

[timed] pos<(l-10) & s>=1 & s<6 -> 1: (pos'=pos+speed); //update position by speed each step

// timed syncronises agent movement with the counters controlling the spawning and despawning of the reward

[] s=1 & pos>=approach_gap -> correct_angle_prob : (_5ht'=1) & (s'=2) + (1-correct_angle_prob) : (missed_reward'=true) & (s'=6); //enter the placefield and increase 5ht (increase to 3!!!)

[] s=2 & pos>=wait_at_gap -> 1 : (_5ht'=3) & (s'=3) & (at_gap'=true); //slow down if front of gap, expected to contain reward

[timed] s=3 & reward_present=true & vis2=0 -> 1 : (vis2'=1); //agent sees reward and 
[timed] s=3 & pos>=(l-10) -> 1: (s'=4); //agent reaches reward location; update state counter

[timed] s=4 -> 0.2: (orientation_correct'=true) & (s'=5) + 0.8 : (orientation_correct'=false) & (s'=4); //correct orientation to get to reward location

[timed] s=5 & orientation_correct=true & reward_present=true -> (collected_reward' = true);
[timed] s=5 & orientation_correct=true & reward_present=false -> (missed_reward'=true);

[] collected_reward=true -> 1: (s'=6);
[] missed_reward=true -> 1: (s'=6);





endmodule 

module reward_spawner

c1 : [0..delay] init 0; //reward spawn delay counter
c2 : [0..reward_lifetime] init 0; //reward lifetime counter
spwnd : bool init false;
despwnd : bool init false;

[timed] at_gap=false -> 1: (c1'=0);
[timed] at_gap=true & spwnd=false & c1=delay -> 1 : (spwnd'=true) & (c1'=0); //spawn reward after "delay" steps
[timed] at_gap=true & spwnd=false & c1<delay-> 1: (c1'=c1+1);  //increment reward spawn counter

[timed] at_gap=true & spwnd=true & c2=reward_lifetime -> 1 : (despwnd'=true); //despawn reward after "reward_lifetime" steps
[timed] at_gap=true & spwnd=true & c2<reward_lifetime -> 1 : (c2'=c2+1); //increment reward despawn counter

[] spwnd=true & despwnd=false -> 1: (reward_present'=true); //spawn reward
[] despwnd=true -> 1: (reward_present'=false); //despawn reward

endmodule





formula x = vis1 + vis2; //speed based on visual inputs

formula speed = ((_5ht=0 & x=1)?5:(_5ht=1 & x=1)?6:(_5ht=1 & x=2)?8:(_5ht=3 & x=1)?1:(_5ht=3 & x=2)?10:0);//speed lookup based on Figure 3 in Bernd paper
